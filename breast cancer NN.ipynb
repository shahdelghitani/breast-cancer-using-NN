{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (70.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install setuptools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: keras in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\skynet\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\skynet\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\skynet\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement distutils (from versions: none)\n",
      "ERROR: No matching distribution found for distutils\n"
     ]
    }
   ],
   "source": [
    "pip install distutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\skynet\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\skynet\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\skynet\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\skynet\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"c:\\Users\\skynet\\AppData\\Local\\Temp\\Rar$DRa20252.28087\\data.csv\" ,  delimiter=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M        17.99         10.38          122.80     1001.0   \n",
       "1     842517         M        20.57         17.77          132.90     1326.0   \n",
       "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3   84348301         M        11.42         20.38           77.58      386.1   \n",
       "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5     843786         M        12.45         15.70           82.57      477.1   \n",
       "6     844359         M        18.25         19.98          119.60     1040.0   \n",
       "7   84458202         M        13.71         20.83           90.20      577.9   \n",
       "8     844981         M        13.00         21.82           87.50      519.8   \n",
       "9   84501001         M        12.46         24.04           83.97      475.9   \n",
       "10    845636         M        16.02         23.24          102.70      797.8   \n",
       "11  84610002         M        15.78         17.89          103.60      781.0   \n",
       "12    846226         M        19.17         24.80          132.40     1123.0   \n",
       "13    846381         M        15.85         23.95          103.70      782.7   \n",
       "14  84667401         M        13.73         22.61           93.60      578.3   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.11840           0.27760         0.30010              0.14710   \n",
       "1           0.08474           0.07864         0.08690              0.07017   \n",
       "2           0.10960           0.15990         0.19740              0.12790   \n",
       "3           0.14250           0.28390         0.24140              0.10520   \n",
       "4           0.10030           0.13280         0.19800              0.10430   \n",
       "5           0.12780           0.17000         0.15780              0.08089   \n",
       "6           0.09463           0.10900         0.11270              0.07400   \n",
       "7           0.11890           0.16450         0.09366              0.05985   \n",
       "8           0.12730           0.19320         0.18590              0.09353   \n",
       "9           0.11860           0.23960         0.22730              0.08543   \n",
       "10          0.08206           0.06669         0.03299              0.03323   \n",
       "11          0.09710           0.12920         0.09954              0.06606   \n",
       "12          0.09740           0.24580         0.20650              0.11180   \n",
       "13          0.08401           0.10020         0.09938              0.05364   \n",
       "14          0.11310           0.22930         0.21280              0.08025   \n",
       "\n",
       "    ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0   ...          17.33           184.60      2019.0            0.1622   \n",
       "1   ...          23.41           158.80      1956.0            0.1238   \n",
       "2   ...          25.53           152.50      1709.0            0.1444   \n",
       "3   ...          26.50            98.87       567.7            0.2098   \n",
       "4   ...          16.67           152.20      1575.0            0.1374   \n",
       "5   ...          23.75           103.40       741.6            0.1791   \n",
       "6   ...          27.66           153.20      1606.0            0.1442   \n",
       "7   ...          28.14           110.60       897.0            0.1654   \n",
       "8   ...          30.73           106.20       739.3            0.1703   \n",
       "9   ...          40.68            97.65       711.4            0.1853   \n",
       "10  ...          33.88           123.80      1150.0            0.1181   \n",
       "11  ...          27.28           136.50      1299.0            0.1396   \n",
       "12  ...          29.94           151.70      1332.0            0.1037   \n",
       "13  ...          27.66           112.00       876.5            0.1131   \n",
       "14  ...          32.01           108.80       697.7            0.1651   \n",
       "\n",
       "    compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.6656           0.7119               0.26540          0.4601   \n",
       "1              0.1866           0.2416               0.18600          0.2750   \n",
       "2              0.4245           0.4504               0.24300          0.3613   \n",
       "3              0.8663           0.6869               0.25750          0.6638   \n",
       "4              0.2050           0.4000               0.16250          0.2364   \n",
       "5              0.5249           0.5355               0.17410          0.3985   \n",
       "6              0.2576           0.3784               0.19320          0.3063   \n",
       "7              0.3682           0.2678               0.15560          0.3196   \n",
       "8              0.5401           0.5390               0.20600          0.4378   \n",
       "9              1.0580           1.1050               0.22100          0.4366   \n",
       "10             0.1551           0.1459               0.09975          0.2948   \n",
       "11             0.5609           0.3965               0.18100          0.3792   \n",
       "12             0.3903           0.3639               0.17670          0.3176   \n",
       "13             0.1924           0.2322               0.11190          0.2809   \n",
       "14             0.7725           0.6943               0.22080          0.3596   \n",
       "\n",
       "    fractal_dimension_worst  Unnamed: 32  \n",
       "0                   0.11890          NaN  \n",
       "1                   0.08902          NaN  \n",
       "2                   0.08758          NaN  \n",
       "3                   0.17300          NaN  \n",
       "4                   0.07678          NaN  \n",
       "5                   0.12440          NaN  \n",
       "6                   0.08368          NaN  \n",
       "7                   0.11510          NaN  \n",
       "8                   0.10720          NaN  \n",
       "9                   0.20750          NaN  \n",
       "10                  0.08452          NaN  \n",
       "11                  0.10480          NaN  \n",
       "12                  0.10230          NaN  \n",
       "13                  0.06287          NaN  \n",
       "14                  0.14310          NaN  \n",
       "\n",
       "[15 rows x 33 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Time             0\n",
       "CO(GT)           0\n",
       "PT08.S1(CO)      0\n",
       "NMHC(GT)         0\n",
       "C6H6(GT)         0\n",
       "PT08.S2(NMHC)    0\n",
       "NOx(GT)          0\n",
       "PT08.S3(NOx)     0\n",
       "NO2(GT)          0\n",
       "PT08.S4(NO2)     0\n",
       "PT08.S5(O3)      0\n",
       "T                0\n",
       "RH               0\n",
       "AH               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Enc_Unnamed: 32', 'Enc_Enc_id', 'Enc_Enc_diagnosis',\n",
       "       'Enc_Enc_radius_mean', 'Enc_Enc_texture_mean', 'Enc_Enc_perimeter_mean',\n",
       "       'Enc_Enc_area_mean', 'Enc_Enc_smoothness_mean',\n",
       "       'Enc_Enc_compactness_mean', 'Enc_Enc_concavity_mean',\n",
       "       'Enc_Enc_concave points_mean', 'Enc_Enc_symmetry_mean',\n",
       "       'Enc_Enc_fractal_dimension_mean', 'Enc_Enc_radius_se',\n",
       "       'Enc_Enc_texture_se', 'Enc_Enc_perimeter_se', 'Enc_Enc_area_se',\n",
       "       'Enc_Enc_smoothness_se', 'Enc_Enc_compactness_se',\n",
       "       'Enc_Enc_concavity_se', 'Enc_Enc_concave points_se',\n",
       "       'Enc_Enc_symmetry_se', 'Enc_Enc_fractal_dimension_se',\n",
       "       'Enc_Enc_radius_worst', 'Enc_Enc_texture_worst',\n",
       "       'Enc_Enc_perimeter_worst', 'Enc_Enc_area_worst',\n",
       "       'Enc_Enc_smoothness_worst', 'Enc_Enc_compactness_worst',\n",
       "       'Enc_Enc_concavity_worst', 'Enc_Enc_concave points_worst',\n",
       "       'Enc_Enc_symmetry_worst', 'Enc_Enc_fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Convert categorical to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalcolumns = ['Unnamed: 32', 'Enc_id', 'Enc_diagnosis', 'Enc_radius_mean',\n",
    "       'Enc_texture_mean', 'Enc_perimeter_mean', 'Enc_area_mean',\n",
    "       'Enc_smoothness_mean', 'Enc_compactness_mean', 'Enc_concavity_mean',\n",
    "       'Enc_concave points_mean', 'Enc_symmetry_mean',\n",
    "       'Enc_fractal_dimension_mean', 'Enc_radius_se', 'Enc_texture_se',\n",
    "       'Enc_perimeter_se', 'Enc_area_se', 'Enc_smoothness_se',\n",
    "       'Enc_compactness_se', 'Enc_concavity_se', 'Enc_concave points_se',\n",
    "       'Enc_symmetry_se', 'Enc_fractal_dimension_se', 'Enc_radius_worst',\n",
    "       'Enc_texture_worst', 'Enc_perimeter_worst', 'Enc_area_worst',\n",
    "       'Enc_smoothness_worst', 'Enc_compactness_worst', 'Enc_concavity_worst',\n",
    "       'Enc_concave points_worst', 'Enc_symmetry_worst',\n",
    "       'Enc_fractal_dimension_worst' ]\n",
    "for i in categoricalcolumns :\n",
    "    dict = {i:j for i,j in zip(data[i].unique(),range(data[i].nunique())) }\n",
    "    data[f'Enc_{i}'] = data[i].map(dict)\n",
    "    data.drop([i] , axis= 1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 32                    float64\n",
       "Enc_id                           int64\n",
       "Enc_diagnosis                    int64\n",
       "Enc_radius_mean                  int64\n",
       "Enc_texture_mean                 int64\n",
       "Enc_perimeter_mean               int64\n",
       "Enc_area_mean                    int64\n",
       "Enc_smoothness_mean              int64\n",
       "Enc_compactness_mean             int64\n",
       "Enc_concavity_mean               int64\n",
       "Enc_concave points_mean          int64\n",
       "Enc_symmetry_mean                int64\n",
       "Enc_fractal_dimension_mean       int64\n",
       "Enc_radius_se                    int64\n",
       "Enc_texture_se                   int64\n",
       "Enc_perimeter_se                 int64\n",
       "Enc_area_se                      int64\n",
       "Enc_smoothness_se                int64\n",
       "Enc_compactness_se               int64\n",
       "Enc_concavity_se                 int64\n",
       "Enc_concave points_se            int64\n",
       "Enc_symmetry_se                  int64\n",
       "Enc_fractal_dimension_se         int64\n",
       "Enc_radius_worst                 int64\n",
       "Enc_texture_worst                int64\n",
       "Enc_perimeter_worst              int64\n",
       "Enc_area_worst                   int64\n",
       "Enc_smoothness_worst             int64\n",
       "Enc_compactness_worst            int64\n",
       "Enc_concavity_worst              int64\n",
       "Enc_concave points_worst         int64\n",
       "Enc_symmetry_worst               int64\n",
       "Enc_fractal_dimension_worst      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skynet\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,593</span> (37.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,593\u001b[0m (37.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,593</span> (37.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,593\u001b[0m (37.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(8, input_shape=(14,), activation='relu'),  \n",
    "    keras.layers.Dense(64, activation='relu'),   \n",
    "    keras.layers.Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "keras_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skynet\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.6897 - val_accuracy: 0.6731 - val_loss: 0.6780\n",
      "Epoch 2/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5877 - loss: 0.6851 - val_accuracy: 0.6731 - val_loss: 0.6676\n",
      "Epoch 3/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6056 - loss: 0.6782 - val_accuracy: 0.6731 - val_loss: 0.6599\n",
      "Epoch 4/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6500 - loss: 0.6642 - val_accuracy: 0.6731 - val_loss: 0.6550\n",
      "Epoch 5/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 0.6725 - val_accuracy: 0.6731 - val_loss: 0.6515\n",
      "Epoch 6/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.6709 - val_accuracy: 0.6731 - val_loss: 0.6486\n",
      "Epoch 7/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 0.6820 - val_accuracy: 0.6731 - val_loss: 0.6462\n",
      "Epoch 8/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6556 - loss: 0.6526 - val_accuracy: 0.6731 - val_loss: 0.6450\n",
      "Epoch 9/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5682 - loss: 0.6854 - val_accuracy: 0.6731 - val_loss: 0.6438\n",
      "Epoch 10/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.6527 - val_accuracy: 0.6731 - val_loss: 0.6431\n",
      "Epoch 11/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6194 - loss: 0.6651 - val_accuracy: 0.6731 - val_loss: 0.6420\n",
      "Epoch 12/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 0.6667 - val_accuracy: 0.6731 - val_loss: 0.6418\n",
      "Epoch 13/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.6757 - val_accuracy: 0.6731 - val_loss: 0.6413\n",
      "Epoch 14/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5803 - loss: 0.6819 - val_accuracy: 0.6731 - val_loss: 0.6408\n",
      "Epoch 15/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6287 - loss: 0.6606 - val_accuracy: 0.6731 - val_loss: 0.6407\n",
      "Epoch 16/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6380 - loss: 0.6564 - val_accuracy: 0.6731 - val_loss: 0.6404\n",
      "Epoch 17/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6042 - loss: 0.6715 - val_accuracy: 0.6731 - val_loss: 0.6404\n",
      "Epoch 18/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 0.6688 - val_accuracy: 0.6731 - val_loss: 0.6401\n",
      "Epoch 19/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6343 - loss: 0.6579 - val_accuracy: 0.6731 - val_loss: 0.6402\n",
      "Epoch 20/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6139 - loss: 0.6671 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 21/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 0.6610 - val_accuracy: 0.6731 - val_loss: 0.6400\n",
      "Epoch 22/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 0.6850 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 23/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 0.6756 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 24/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6304 - loss: 0.6595 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 25/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6264 - loss: 0.6614 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 26/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5909 - loss: 0.6778 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 27/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5778 - loss: 0.6837 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 28/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6314 - loss: 0.6591 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 29/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6178 - loss: 0.6653 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 30/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6385 - loss: 0.6557 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 31/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6289 - loss: 0.6601 - val_accuracy: 0.6731 - val_loss: 0.6401\n",
      "Epoch 32/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 0.6874 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 33/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.6752 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 34/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.6753 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 35/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.6683 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 36/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: 0.6558 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 37/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 0.6550 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 38/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6184 - loss: 0.6651 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 39/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6561 - loss: 0.6475 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 40/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 0.6733 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 41/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5896 - loss: 0.6782 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 42/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.6723 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 43/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 0.6670 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 44/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 0.6559 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 45/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6266 - loss: 0.6613 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 46/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6345 - loss: 0.6576 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 47/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 0.6610 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 48/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5959 - loss: 0.6754 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 49/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 0.6837 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 50/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6371 - loss: 0.6563 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 51/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 0.6739 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 52/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.6794 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 53/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6129 - loss: 0.6675 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 54/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6395 - loss: 0.6551 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 55/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5410 - loss: 0.7003 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 56/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6395 - loss: 0.6552 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 57/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5878 - loss: 0.6791 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 58/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.6730 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 59/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6266 - loss: 0.6613 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 60/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 0.6724 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 61/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6345 - loss: 0.6577 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 62/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6013 - loss: 0.6730 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 63/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5970 - loss: 0.6748 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 64/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 0.6624 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 65/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.6723 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 66/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5918 - loss: 0.6772 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 67/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 0.6589 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 68/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 0.6727 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 69/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5590 - loss: 0.6924 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 70/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.6670 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 71/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6144 - loss: 0.6670 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 72/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6124 - loss: 0.6678 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 73/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6248 - loss: 0.6621 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 74/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5783 - loss: 0.6836 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 75/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 0.6724 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 76/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.6768 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 77/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 0.6717 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 78/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6284 - loss: 0.6604 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 79/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6261 - loss: 0.6615 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 80/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6382 - loss: 0.6559 - val_accuracy: 0.6731 - val_loss: 0.6396\n",
      "Epoch 81/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6296 - loss: 0.6599 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 82/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6184 - loss: 0.6651 - val_accuracy: 0.6731 - val_loss: 0.6397\n",
      "Epoch 83/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6187 - loss: 0.6649 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 84/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6174 - loss: 0.6655 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 85/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5988 - loss: 0.6741 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 86/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6064 - loss: 0.6706 - val_accuracy: 0.6731 - val_loss: 0.6395\n",
      "Epoch 87/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 0.6661 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 88/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6368 - loss: 0.6566 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 89/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6529 - loss: 0.6491 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 90/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6191 - loss: 0.6647 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 91/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6472 - loss: 0.6517 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 92/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.6765 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 93/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6087 - loss: 0.6695 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 94/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 0.6800 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 95/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6168 - loss: 0.6658 - val_accuracy: 0.6731 - val_loss: 0.6400\n",
      "Epoch 96/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6197 - loss: 0.6645 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 97/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5925 - loss: 0.6770 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 98/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6355 - loss: 0.6572 - val_accuracy: 0.6731 - val_loss: 0.6398\n",
      "Epoch 99/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.6744 - val_accuracy: 0.6731 - val_loss: 0.6399\n",
      "Epoch 100/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 0.6721 - val_accuracy: 0.6731 - val_loss: 0.6399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data.drop(columns=['Enc_Enc_diagnosis']) \n",
    "y = data['Enc_Enc_diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "keras_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = keras_model.fit(X_train, y_train, epochs=100, batch_size=1, validation_split=0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.save('airquality.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "[[0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]\n",
      " [0.6125956]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = keras_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Evaluate Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6762 - loss: 0.6384 \n",
      "Loss: 0.6267170906066895\n",
      "Accuracy: 0.7017543911933899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = keras_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizing Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y_pred_binary = (y_pred > 0.5).astype(int) \n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Not Infected', 'Infected'], yticklabels=['Not Infected', 'Infected'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
